{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Please do HW1 in Jupyter Notebook using Python. Submit an HTML file and ipynb file following the link in Modules, and then HW1, and finally clicking the submit button to access files on your computer. When working on the HWs, please do not display unnecessary data unless it is asked. Each problem is with 20 points.\n",
    "##### Due on 9/3/2021, Friday at 11:59 pm in Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. \n",
    "The longest known word in the English language is given by pneumonoultramicroscopicsilicovolcanoconiosisis. You can google to find out what it means.  Read more about dictionaries here https://docs.python.org/3/tutorial/datastructures.html#dictionaries  and sets in python here https://www.geeksforgeeks.org/sets-in-python/.\n",
    "\n",
    "a) Using python in Jupyter notebook, make a list of all the letters in this word. \n",
    "\n",
    "b) Change the list in (a)  to a set to find out a unique set of alphabets used in this word.  \n",
    "\n",
    "c) Considering a set U of 26 English alphabets as a Universal set, find the complement of the set in (b) using python.\n",
    "\n",
    "d) Create a dictionary with these unique letters in the set (b) as keys and the number of times these letters appear in the word as values. Your dictionary should look like $D=\\{a: 2, c:6,\\cdots\\cdot\\cdots\\}$ as a appears 2 times, and c appears 6 times in the original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Problem 1 here.Add cells asneeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_long_word=list('pneumonoultramicroscopicsilicovolcanoconiosisis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes a sorted list of the letter of the word \"pneumonoultramicroscopicsilicovolcanoconiosisis\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'c', 'c', 'c', 'c', 'c', 'c', 'e', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'l', 'l', 'l', 'm', 'm', 'n', 'n', 'n', 'n', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'p', 'p', 'r', 'r', 's', 's', 's', 's', 's', 't', 'u', 'u', 'v']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(list_long_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns that list into a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_long_word=set(list_long_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'e', 'i', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(set_long_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm creating a set of all of the letters of the alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters=set(\"abcdefghijklmnopqrstuwxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a set of all of the letters that aren't in \"pneumonoultramicroscopicsilicovolcanoconiosisis\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "complement=letters-set_long_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'd', 'f', 'g', 'h', 'j', 'k', 'q', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(complement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a dictionary of the letters in \"pneumonoultramicroscopicsilicovolcanoconiosisis\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "D={x:sorted(list_long_word).count(x) for x in sorted(list_long_word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 2, 'c': 6, 'e': 1, 'i': 7, 'l': 3, 'm': 2, 'n': 4, 'o': 9, 'p': 2, 'r': 2, 's': 5, 't': 1, 'u': 2, 'v': 1}\n"
     ]
    }
   ],
   "source": [
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Another word, supercalifragilisticexpialidocious, has 34 letters. Find a set B of unique letters in this word. Let‚Äôs denote a set you found in problem 1(b) by A. Do the following using python in Jupyter notebook.  \n",
    "\n",
    "a) Find the union and intersection of A and B.\n",
    "\n",
    "b) Find  and $A-B, B-A$ and $A\\Delta B$.\n",
    "\n",
    "c) Verify and find out if the statement $A-B = A\\cap B^c$ or $A-B = A^c\\cap B$ is true.\n",
    "\n",
    "d) Verify both De Morgan‚Äôs law for set theory for A and B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2 solution goes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm making the set of letters in \"pneumonoultramicroscopicsilicovolcanoconiosisis\" easier to use than \"set_long_word\".\n",
    "A=set_long_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm making a set of the letters in \"supercalifragilisticexpialidocious\".\n",
    "B=set('supercalifragilisticexpialidocious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'd', 'e', 'f', 'g', 'i', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'x']\n"
     ]
    }
   ],
   "source": [
    "# The letters in either word.\n",
    "print(sorted(A.union(B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'e', 'i', 'l', 'o', 'p', 'r', 's', 't', 'u']\n"
     ]
    }
   ],
   "source": [
    "# The letters shared between the words.\n",
    "print(sorted(A.intersection(B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m', 'n', 'v']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(A-B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', 'f', 'g', 'x']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(B-A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', 'f', 'g', 'm', 'n', 'v', 'x']\n"
     ]
    }
   ],
   "source": [
    "# Here is one way to do ùê¥Œîùêµ.\n",
    "print(sorted((A-B).union(B-A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', 'f', 'g', 'm', 'n', 'v', 'x']\n"
     ]
    }
   ],
   "source": [
    "# Here is another way to do ùê¥Œîùêµ.\n",
    "print(sorted((A.union(B))-(A.intersection(B))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A-B==A.intersection(letters-B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A-B==(letters-A).intersection(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify De Morgan‚Äôs law.\n",
    "letters-(A.union(B))==(letters-A).intersection(letters-B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify De Morgan‚Äôs law.\n",
    "letters-(A.intersection(B))==(letters-A).union(letters-B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Upload the .csv file titanic.csv that came with this HW in the notebook by following instructions here https://www.datacamp.com/community/tutorials/pandas-read-csv and name it as titanic. Make sure to import panda as pd and numpy as np.  Read the details about the titanic data here https://data.world/nrippner/titanic-disaster-dataset Answer the following questions. Learn more about the Boolean mask https://stackoverflow.com/questions/38802675/create-bool-mask-from-filter-results-in-pandas about filtering data.\n",
    "\n",
    "a) What happens If you type isna(titanic.cabin).any() and run it? Explain how this is related to either the disjunction or the conjunction in logic lecture we did.\n",
    "\n",
    "b) How many passengers who paid the minimum fare survived? Hint- Statement p: Passenger survived. Statement q: Passenger paid the minimum fare.\n",
    "\n",
    "c) What was the name of the female who was traveling in the first class from Cherbourg to Cooperstown, NY, and was 18 or younger? (full credit will be given to a solution that combines multiple statements using and/or and is a one-line code.)\n",
    "\n",
    "d) Did anybody who didn‚Äôt pay any fare, had no cabin and didn‚Äôt have a destination survive?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd # This is the package we used already. \n",
    "import numpy as np \n",
    "# Numpy is another python package that delas with numerical python.\n",
    "#Learn more about it here https://numpy.org/. No need to download as\n",
    "# it is inlcuded in the anaconda package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gave me trouble as I didn'y realise I had my name in my own computer as \"march\" rather than \"marc\".\n",
    "titanic=pd.read_csv('C:/Users/march/Home Work/titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pclass  survived                                             name  \\\n",
      "0        1.0       1.0                    Allen, Miss. Elisabeth Walton   \n",
      "1        1.0       1.0                   Allison, Master. Hudson Trevor   \n",
      "2        1.0       0.0                     Allison, Miss. Helen Loraine   \n",
      "3        1.0       0.0             Allison, Mr. Hudson Joshua Creighton   \n",
      "4        1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)   \n",
      "...      ...       ...                                              ...   \n",
      "1305     3.0       0.0                            Zabour, Miss. Thamine   \n",
      "1306     3.0       0.0                        Zakarian, Mr. Mapriededer   \n",
      "1307     3.0       0.0                              Zakarian, Mr. Ortin   \n",
      "1308     3.0       0.0                               Zimmerman, Mr. Leo   \n",
      "1309     NaN       NaN                                              NaN   \n",
      "\n",
      "         sex      age  sibsp  parch  ticket      fare    cabin embarked boat  \\\n",
      "0     female  29.0000    0.0    0.0   24160  211.3375       B5        S    2   \n",
      "1       male   0.9167    1.0    2.0  113781  151.5500  C22 C26        S   11   \n",
      "2     female   2.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN   \n",
      "3       male  30.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN   \n",
      "4     female  25.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN   \n",
      "...      ...      ...    ...    ...     ...       ...      ...      ...  ...   \n",
      "1305  female      NaN    1.0    0.0    2665   14.4542      NaN        C  NaN   \n",
      "1306    male  26.5000    0.0    0.0    2656    7.2250      NaN        C  NaN   \n",
      "1307    male  27.0000    0.0    0.0    2670    7.2250      NaN        C  NaN   \n",
      "1308    male  29.0000    0.0    0.0  315082    7.8750      NaN        S  NaN   \n",
      "1309     NaN      NaN    NaN    NaN     NaN       NaN      NaN      NaN  NaN   \n",
      "\n",
      "       body                        home.dest  \n",
      "0       NaN                     St Louis, MO  \n",
      "1       NaN  Montreal, PQ / Chesterville, ON  \n",
      "2       NaN  Montreal, PQ / Chesterville, ON  \n",
      "3     135.0  Montreal, PQ / Chesterville, ON  \n",
      "4       NaN  Montreal, PQ / Chesterville, ON  \n",
      "...     ...                              ...  \n",
      "1305    NaN                              NaN  \n",
      "1306  304.0                              NaN  \n",
      "1307    NaN                              NaN  \n",
      "1308    NaN                              NaN  \n",
      "1309    NaN                              NaN  \n",
      "\n",
      "[1310 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'isna' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-181-c2a740dccb30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'isna' is not defined"
     ]
    }
   ],
   "source": [
    "# I'm not exactly sure what is going on with this.\n",
    "isna(titanic.cabin).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is saying that there is atleast one NA value in cabin.\n",
    "titanic.cabin.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not sure what the minimum fare was, but googling it I found it to be $15.Though I'm not sure what units our data is in.\n",
    "survived_fare=(titanic['survived']==1) & (titanic['fare']>15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Anderson, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19952</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>E12</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D7</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hudson, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Appleton, Mrs. Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayside, Queens, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thorneycroft, Mrs. Percival (Florence Kate White)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376564</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Touma, Master. Georges Youssef</td>\n",
       "      <td>male</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2650</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Touma, Miss. Maria Youssef</td>\n",
       "      <td>female</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2650</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Touma, Mrs. Darwis (Hanne Youssef Razi)</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2650</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived                                               name  \\\n",
       "0        1.0       1.0                      Allen, Miss. Elisabeth Walton   \n",
       "1        1.0       1.0                     Allison, Master. Hudson Trevor   \n",
       "5        1.0       1.0                                Anderson, Mr. Harry   \n",
       "6        1.0       1.0                  Andrews, Miss. Kornelia Theodosia   \n",
       "8        1.0       1.0      Appleton, Mrs. Edward Dale (Charlotte Lamson)   \n",
       "...      ...       ...                                                ...   \n",
       "1189     3.0       1.0                    Sandstrom, Miss. Marguerite Rut   \n",
       "1247     3.0       1.0  Thorneycroft, Mrs. Percival (Florence Kate White)   \n",
       "1256     3.0       1.0                     Touma, Master. Georges Youssef   \n",
       "1257     3.0       1.0                         Touma, Miss. Maria Youssef   \n",
       "1258     3.0       1.0            Touma, Mrs. Darwis (Hanne Youssef Razi)   \n",
       "\n",
       "         sex      age  sibsp  parch   ticket      fare    cabin embarked boat  \\\n",
       "0     female  29.0000    0.0    0.0    24160  211.3375       B5        S    2   \n",
       "1       male   0.9167    1.0    2.0   113781  151.5500  C22 C26        S   11   \n",
       "5       male  48.0000    0.0    0.0    19952   26.5500      E12        S    3   \n",
       "6     female  63.0000    1.0    0.0    13502   77.9583       D7        S   10   \n",
       "8     female  53.0000    2.0    0.0    11769   51.4792     C101        S    D   \n",
       "...      ...      ...    ...    ...      ...       ...      ...      ...  ...   \n",
       "1189  female   4.0000    1.0    1.0  PP 9549   16.7000       G6        S   13   \n",
       "1247  female      NaN    1.0    0.0   376564   16.1000      NaN        S   10   \n",
       "1256    male   7.0000    1.0    1.0     2650   15.2458      NaN        C    C   \n",
       "1257  female   9.0000    1.0    1.0     2650   15.2458      NaN        C    C   \n",
       "1258  female  29.0000    0.0    2.0     2650   15.2458      NaN        C    C   \n",
       "\n",
       "      body                        home.dest  \n",
       "0      NaN                     St Louis, MO  \n",
       "1      NaN  Montreal, PQ / Chesterville, ON  \n",
       "5      NaN                     New York, NY  \n",
       "6      NaN                       Hudson, NY  \n",
       "8      NaN              Bayside, Queens, NY  \n",
       "...    ...                              ...  \n",
       "1189   NaN                              NaN  \n",
       "1247   NaN                              NaN  \n",
       "1256   NaN                              NaN  \n",
       "1257   NaN                              NaN  \n",
       "1258   NaN                              NaN  \n",
       "\n",
       "[330 rows x 14 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 330 passengers who paid a fare of at least $15 survived.\n",
    "titanic[survived_fare]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery=(titanic['sex']=='female')&(titanic['pclass']==1)&((titanic['age']==18)|(titanic['age']<18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Astor, Mrs. John Jacob (Madeleine Talmadge Force)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>C62 C64</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Carter, Miss. Lucile Polk</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113760</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bryn Mawr, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dick, Mrs. Albert Adrian (Vera Gillespie)</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17474</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>B20</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calgary, AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hippach, Miss. Jean Gertrude</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111361</td>\n",
       "      <td>57.9792</td>\n",
       "      <td>B18</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lines, Miss. Mary Conover</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17592</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>D28</td>\n",
       "      <td>S</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Madill, Miss. Georgette Alexandra</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Maioni, Miss. Roberta</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110152</td>\n",
       "      <td>86.5000</td>\n",
       "      <td>B79</td>\n",
       "      <td>S</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Marvin, Mrs. Daniel Warner (Mary Graham Carmic...</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113773</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>D30</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Penasco y Castellana, Mrs. Victor de Satode (M...</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C65</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Madrid, Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ryerson, Miss. Emily Borie</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haverford, PA / Cooperstown, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Smith, Mrs. Lucien Philip (Mary Eloise Hughes)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13695</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>C31</td>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Huntington, WV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Taussig, Miss. Ruth</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110413</td>\n",
       "      <td>79.6500</td>\n",
       "      <td>E68</td>\n",
       "      <td>S</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  survived                                               name  \\\n",
       "2       1.0       0.0                       Allison, Miss. Helen Loraine   \n",
       "11      1.0       1.0  Astor, Mrs. John Jacob (Madeleine Talmadge Force)   \n",
       "55      1.0       1.0                          Carter, Miss. Lucile Polk   \n",
       "92      1.0       1.0          Dick, Mrs. Albert Adrian (Vera Gillespie)   \n",
       "159     1.0       1.0                       Hippach, Miss. Jean Gertrude   \n",
       "187     1.0       1.0                          Lines, Miss. Mary Conover   \n",
       "193     1.0       1.0                  Madill, Miss. Georgette Alexandra   \n",
       "195     1.0       1.0                              Maioni, Miss. Roberta   \n",
       "198     1.0       1.0  Marvin, Mrs. Daniel Warner (Mary Graham Carmic...   \n",
       "229     1.0       1.0  Penasco y Castellana, Mrs. Victor de Satode (M...   \n",
       "250     1.0       1.0                         Ryerson, Miss. Emily Borie   \n",
       "270     1.0       1.0     Smith, Mrs. Lucien Philip (Mary Eloise Hughes)   \n",
       "289     1.0       1.0                                Taussig, Miss. Ruth   \n",
       "\n",
       "        sex   age  sibsp  parch    ticket      fare            cabin embarked  \\\n",
       "2    female   2.0    1.0    2.0    113781  151.5500          C22 C26        S   \n",
       "11   female  18.0    1.0    0.0  PC 17757  227.5250          C62 C64        C   \n",
       "55   female  14.0    1.0    2.0    113760  120.0000          B96 B98        S   \n",
       "92   female  17.0    1.0    0.0     17474   57.0000              B20        S   \n",
       "159  female  16.0    0.0    1.0    111361   57.9792              B18        C   \n",
       "187  female  16.0    0.0    1.0  PC 17592   39.4000              D28        S   \n",
       "193  female  15.0    0.0    1.0     24160  211.3375               B5        S   \n",
       "195  female  16.0    0.0    0.0    110152   86.5000              B79        S   \n",
       "198  female  18.0    1.0    0.0    113773   53.1000              D30        S   \n",
       "229  female  17.0    1.0    0.0  PC 17758  108.9000              C65        C   \n",
       "250  female  18.0    2.0    2.0  PC 17608  262.3750  B57 B59 B63 B66        C   \n",
       "270  female  18.0    1.0    0.0     13695   60.0000              C31        S   \n",
       "289  female  18.0    0.0    2.0    110413   79.6500              E68        S   \n",
       "\n",
       "    boat  body                        home.dest  \n",
       "2    NaN   NaN  Montreal, PQ / Chesterville, ON  \n",
       "11     4   NaN                     New York, NY  \n",
       "55     4   NaN                    Bryn Mawr, PA  \n",
       "92     3   NaN                      Calgary, AB  \n",
       "159    4   NaN                      Chicago, IL  \n",
       "187    9   NaN                    Paris, France  \n",
       "193    2   NaN                     St Louis, MO  \n",
       "195    8   NaN                              NaN  \n",
       "198   10   NaN                     New York, NY  \n",
       "229    8   NaN                    Madrid, Spain  \n",
       "250    4   NaN  Haverford, PA / Cooperstown, NY  \n",
       "270    6   NaN                   Huntington, WV  \n",
       "289    8   NaN                     New York, NY  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There were only 8 females 18 or under that were in the first class,\n",
    "# and none of them were traveling from Cherbourg to Cooperstown, NY.\n",
    "# However, Emily Borie Ryerson's (250) destination was Cooperstown, NY.\n",
    "titanic[mystery]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4. \n",
    "Continuing with the titanic data set, answer the following questions.\n",
    "\n",
    "a) Filter the titanic data with the condition that $|\\text{fare} - \\text{mean(fare)}|< 0.5$ (the sign | is absolute value sign here) and get a subset of the titanic data.\n",
    "\n",
    "b) Excluding the NaN values for the variable ticket, find out how many tickets were used by more than a passenger?\n",
    "\n",
    "c) Create a new column with a column name ‚Äúluck‚Äù  in the titanic data set with the following rules. Let‚Äôs call a passenger ‚Äúunlucky‚Äù if the passenger was in the first-class, paid more than the average fare, and did not survive.  On the contrary, a passenger is ‚Äúlucky‚Äù if the passenger was not in the first class, paid less or equal to the average fare, and survived. Let‚Äôs call everybody else ‚Äúaverageluck‚Äù.  Show the head of the data with a visible luck column.\n",
    "\n",
    "d) Find the number of lucky, unlucky, and passengers with average luck using a groupby function https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1308.000000\n",
       "mean       33.295479\n",
       "std        51.758668\n",
       "min         0.000000\n",
       "25%         7.895800\n",
       "50%        14.454200\n",
       "75%        31.275000\n",
       "max       512.329200\n",
       "Name: fare, dtype: float64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert type 'str' to numerator/denominator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-383-231c4055b5c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# I can't figure out what is wrong. I don't know why fare has 0 data points.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmean_fare\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fare'\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fare'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\statistics.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mStatisticsError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean requires at least one data point'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\statistics.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(data, start)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_coerce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# or raise TypeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_exact_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mpartials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartials_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\statistics.py\u001b[0m in \u001b[0;36m_exact_ratio\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"can't convert type '{}' to numerator/denominator\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert type 'str' to numerator/denominator"
     ]
    }
   ],
   "source": [
    "# I can't figure out what is wrong. I don't know why fare has 0 data points.\n",
    "mean_fare=(titanic.abs('fare'-mean('fare'))<0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-430-6ea43ec78e37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean_fare2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fare'\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m33.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "mean_fare2=(titanic.abs('fare'-33.3)<0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>luck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast, NI</td>\n",
       "      <td>unlucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chisholm, Mr. Roderick Robert Crispin</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liverpool, England / Belfast</td>\n",
       "      <td>unlucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fry, Mr. Richard</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B102</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unlucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Harrison, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B94</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unlucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ismay, Mr. Joseph Bruce</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B52 B54 B56</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>unlucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Parr, Mr. William Henry Marsh</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>unlucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Reuchlin, Jonkheer. John George</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rotterdam, Netherlands</td>\n",
       "      <td>unlucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Campbell, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cunningham, Mr. Alfred Fleming</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frost, Mr. Anthony Wood \"Archie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Knight, Mr. Robert J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Parkes, Mr. Francis \"Frank\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Watson, Mr. Ennis Hastings</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Johnson, Mr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Johnson, Mr. William Cahoone Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Leonard, Mr. Lionel</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tornquist, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived                                   name   sex   age  \\\n",
       "7        1.0       0.0                 Andrews, Mr. Thomas Jr  male  39.0   \n",
       "70       1.0       0.0  Chisholm, Mr. Roderick Robert Crispin  male   NaN   \n",
       "125      1.0       0.0                       Fry, Mr. Richard  male   NaN   \n",
       "150      1.0       0.0                  Harrison, Mr. William  male  40.0   \n",
       "170      1.0       1.0                Ismay, Mr. Joseph Bruce  male  49.0   \n",
       "223      1.0       0.0          Parr, Mr. William Henry Marsh  male   NaN   \n",
       "234      1.0       0.0        Reuchlin, Jonkheer. John George  male  38.0   \n",
       "363      2.0       0.0                  Campbell, Mr. William  male   NaN   \n",
       "384      2.0       0.0         Cunningham, Mr. Alfred Fleming  male   NaN   \n",
       "410      2.0       0.0       Frost, Mr. Anthony Wood \"Archie\"  male   NaN   \n",
       "473      2.0       0.0                   Knight, Mr. Robert J  male   NaN   \n",
       "528      2.0       0.0            Parkes, Mr. Francis \"Frank\"  male   NaN   \n",
       "581      2.0       0.0             Watson, Mr. Ennis Hastings  male   NaN   \n",
       "896      3.0       0.0                    Johnson, Mr. Alfred  male  49.0   \n",
       "898      3.0       0.0        Johnson, Mr. William Cahoone Jr  male  19.0   \n",
       "963      3.0       0.0                    Leonard, Mr. Lionel  male  36.0   \n",
       "1254     3.0       1.0           Tornquist, Mr. William Henry  male  25.0   \n",
       "\n",
       "      sibsp  parch  ticket  fare        cabin embarked boat   body  \\\n",
       "7       0.0    0.0  112050   0.0          A36        S  NaN    NaN   \n",
       "70      0.0    0.0  112051   0.0          NaN        S  NaN    NaN   \n",
       "125     0.0    0.0  112058   0.0         B102        S  NaN    NaN   \n",
       "150     0.0    0.0  112059   0.0          B94        S  NaN  110.0   \n",
       "170     0.0    0.0  112058   0.0  B52 B54 B56        S    C    NaN   \n",
       "223     0.0    0.0  112052   0.0          NaN        S  NaN    NaN   \n",
       "234     0.0    0.0   19972   0.0          NaN        S  NaN    NaN   \n",
       "363     0.0    0.0  239853   0.0          NaN        S  NaN    NaN   \n",
       "384     0.0    0.0  239853   0.0          NaN        S  NaN    NaN   \n",
       "410     0.0    0.0  239854   0.0          NaN        S  NaN    NaN   \n",
       "473     0.0    0.0  239855   0.0          NaN        S  NaN    NaN   \n",
       "528     0.0    0.0  239853   0.0          NaN        S  NaN    NaN   \n",
       "581     0.0    0.0  239856   0.0          NaN        S  NaN    NaN   \n",
       "896     0.0    0.0    LINE   0.0          NaN        S  NaN    NaN   \n",
       "898     0.0    0.0    LINE   0.0          NaN        S  NaN    NaN   \n",
       "963     0.0    0.0    LINE   0.0          NaN        S  NaN    NaN   \n",
       "1254    0.0    0.0    LINE   0.0          NaN        S   15    NaN   \n",
       "\n",
       "                         home.dest     luck  \n",
       "7                      Belfast, NI  unlucky  \n",
       "70    Liverpool, England / Belfast  unlucky  \n",
       "125                            NaN  unlucky  \n",
       "150                            NaN  unlucky  \n",
       "170                      Liverpool  unlucky  \n",
       "223                        Belfast  unlucky  \n",
       "234         Rotterdam, Netherlands  unlucky  \n",
       "363                        Belfast    lucky  \n",
       "384                        Belfast    lucky  \n",
       "410                        Belfast    lucky  \n",
       "473                        Belfast    lucky  \n",
       "528                        Belfast    lucky  \n",
       "581                        Belfast    lucky  \n",
       "896                            NaN    lucky  \n",
       "898                            NaN    lucky  \n",
       "963                            NaN    lucky  \n",
       "1254                           NaN    lucky  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WIP\n",
    "titanic[mean_fare]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_fare2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-431-6a8f376e6e03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmean_fare2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_fare2' is not defined"
     ]
    }
   ],
   "source": [
    "titanic[mean_fare2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NaN values\n",
    "titanict=titanic.dropna(subset=['ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA. 2343    11\n",
       "CA 2144      8\n",
       "1601         8\n",
       "PC 17608     7\n",
       "347077       7\n",
       "            ..\n",
       "PC 17603     2\n",
       "2665         2\n",
       "7534         2\n",
       "113789       2\n",
       "2660         2\n",
       "Name: ticket, Length: 216, dtype: int64"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignoring the times tickets were used only once, 216 tickets were used by multiple people.\n",
    "titanict['ticket'].value_counts().loc[lambda x:x>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions for luck column.\n",
    "def conditions(s):\n",
    "    if (titanic['pclass'] == 1) & (titanic['fare'] > 33.3) & (titanic['survived'] == 0):\n",
    "        return 'unlucky'\n",
    "    if (titanic['pclass'] > 1) & (titanic['fare'] <= 33.3) & (titanic['survived'] == 1):\n",
    "        return 'lucky'\n",
    "    else:\n",
    "        return 'averageluck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-436-33f607942480>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# WIP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'luck'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconditions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7767\u001b[0m         )\n\u001b[1;32m-> 7768\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-433-82311c04502c>\u001b[0m in \u001b[0;36mconditions\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Conditions for luck column.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconditions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pclass'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fare'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m33.3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'survived'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'unlucky'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pclass'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fare'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m33.3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'survived'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1442\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1443\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# WIP\n",
    "titanic['luck']=titanic.apply(conditions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       unlucky\n",
       "1       unlucky\n",
       "2       unlucky\n",
       "3       unlucky\n",
       "4       unlucky\n",
       "         ...   \n",
       "1305      lucky\n",
       "1306      lucky\n",
       "1307      lucky\n",
       "1308      lucky\n",
       "1309      lucky\n",
       "Name: luck, Length: 1310, dtype: object"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It looks like it worked?\n",
    "titanic['luck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001AA761A07C0>"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I can't seem to make groupby work.\n",
    "titanic.groupby('luck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lucky      987\n",
       "unlucky    323\n",
       "Name: luck, dtype: int64"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no averageluck. The above didn't work.\n",
    "titanic['luck'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "Write two data frames you see in the picture below in Jupyter notebook. You will have to manually type these and make two data frames DF1 and DF2.\n",
    "\n",
    "a) Create a new data frame using the merge function with left join on ID. Explain which set operation this join corresponds to. You will see that there are some NaN values in the new data frame. Explain why? Read more about joins and concatenation here. \n",
    "\n",
    "b) Do the same as in (a) with right join. \n",
    "\n",
    "c) Do the same as in (a) with the inner join. Why are there no NaNs here?\n",
    "\n",
    "d) Do the same as in (a) with an outer join.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s05</td>\n",
       "      <td>Carl</td>\n",
       "      <td>Iowa City</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s06</td>\n",
       "      <td>Luke</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s08</td>\n",
       "      <td>David</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Name         City  Age\n",
       "0  s01  Julie   Des Moines   25\n",
       "1  s05   Carl    Iowa City   34\n",
       "2  s06   Luke      Chicago   29\n",
       "3  s08  David  Minneapolis   45"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = {'ID':['s01','s05','s06', 's08'],\n",
    "    'Name':['Julie', 'Carl', 'Luke', 'David'],\n",
    "    'City': ['Des Moines', 'Iowa City', 'Chicago', 'Minneapolis'],\n",
    "    'Age':[25, 34, 29, 45]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s08</td>\n",
       "      <td>David</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s03</td>\n",
       "      <td>Bradley</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s04</td>\n",
       "      <td>Nina</td>\n",
       "      <td>Pittsburg</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID     Name         City   GPA\n",
       "0  s01    Julie   Des Moines  3.25\n",
       "1  s08    David  Minneapolis  3.30\n",
       "2  s03  Bradley        Tempe  3.40\n",
       "3  s04     Nina    Pittsburg  4.00"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = {'ID':['s01','s08','s03', 's04'],\n",
    "    'Name':['Julie', 'David', 'Bradley', 'Nina'],\n",
    "    'City': ['Des Moines', 'Minneapolis', 'Tempe', 'Pittsburg'],\n",
    "    'GPA':[3.25, 3.3, 3.4, 4]}\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name_x</th>\n",
       "      <th>City_x</th>\n",
       "      <th>Age</th>\n",
       "      <th>Name_y</th>\n",
       "      <th>City_y</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>25</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s05</td>\n",
       "      <td>Carl</td>\n",
       "      <td>Iowa City</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s06</td>\n",
       "      <td>Luke</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s08</td>\n",
       "      <td>David</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>45</td>\n",
       "      <td>David</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Name_x       City_x  Age Name_y       City_y   GPA\n",
       "0  s01  Julie   Des Moines   25  Julie   Des Moines  3.25\n",
       "1  s05   Carl    Iowa City   34    NaN          NaN   NaN\n",
       "2  s06   Luke      Chicago   29    NaN          NaN   NaN\n",
       "3  s08  David  Minneapolis   45  David  Minneapolis  3.30"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge function with left join on ID\n",
    "df1.merge(df2, how='left', on='ID')\n",
    "# This corresponds to df1 union (df1 intersect df2).\n",
    "# The NaN values are because the people from df1 don't have y_names/cities, or a gpa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name_x</th>\n",
       "      <th>City_x</th>\n",
       "      <th>Age</th>\n",
       "      <th>Name_y</th>\n",
       "      <th>City_y</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s08</td>\n",
       "      <td>David</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>45.0</td>\n",
       "      <td>David</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bradley</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nina</td>\n",
       "      <td>Pittsburg</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Name_x       City_x   Age   Name_y       City_y   GPA\n",
       "0  s01  Julie   Des Moines  25.0    Julie   Des Moines  3.25\n",
       "1  s08  David  Minneapolis  45.0    David  Minneapolis  3.30\n",
       "2  s03    NaN          NaN   NaN  Bradley        Tempe  3.40\n",
       "3  s04    NaN          NaN   NaN     Nina    Pittsburg  4.00"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge function with right join on ID\n",
    "df1.merge(df2, how='right', on='ID')\n",
    "# This corresponds to df2 union (df1 intersect df2).\n",
    "# The NaN values are because the people from df2 don't have x_names/cities, or age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name_x</th>\n",
       "      <th>City_x</th>\n",
       "      <th>Age</th>\n",
       "      <th>Name_y</th>\n",
       "      <th>City_y</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>25</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s08</td>\n",
       "      <td>David</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>45</td>\n",
       "      <td>David</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Name_x       City_x  Age Name_y       City_y   GPA\n",
       "0  s01  Julie   Des Moines   25  Julie   Des Moines  3.25\n",
       "1  s08  David  Minneapolis   45  David  Minneapolis  3.30"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge function with inner join on ID\n",
    "df1.merge(df2, how='inner', on='ID')\n",
    "# This corresponds to intersection.\n",
    "# There are no NaN values because we're only looking at what both dataframes share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name_x</th>\n",
       "      <th>City_x</th>\n",
       "      <th>Age</th>\n",
       "      <th>Name_y</th>\n",
       "      <th>City_y</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s05</td>\n",
       "      <td>Carl</td>\n",
       "      <td>Iowa City</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s06</td>\n",
       "      <td>Luke</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s08</td>\n",
       "      <td>David</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>45.0</td>\n",
       "      <td>David</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bradley</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nina</td>\n",
       "      <td>Pittsburg</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Name_x       City_x   Age   Name_y       City_y   GPA\n",
       "0  s01  Julie   Des Moines  25.0    Julie   Des Moines  3.25\n",
       "1  s05   Carl    Iowa City  34.0      NaN          NaN   NaN\n",
       "2  s06   Luke      Chicago  29.0      NaN          NaN   NaN\n",
       "3  s08  David  Minneapolis  45.0    David  Minneapolis  3.30\n",
       "4  s03    NaN          NaN   NaN  Bradley        Tempe  3.40\n",
       "5  s04    NaN          NaN   NaN     Nina    Pittsburg  4.00"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge function with outer join on ID\n",
    "df1.merge(df2, how='outer', on='ID')\n",
    "# This corresponds to union.\n",
    "# The NaN values are because the people from df1 don't have y_names/cities, or a gpa, and df2 don't have x_names/cities, or age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wanted to see how I would do on this with being new to python.\n",
    "# Obviously I struggled and I need to use your office hours for help next time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
